{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5835f940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3060\n",
      "Memory: 12.9 GB\n",
      "Setup completed\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import timm\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seeds(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "def clear_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Setup completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9acd8134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streamlined Steel Defect Detection\n",
      "Data root: NEU-DET\n",
      "Backbone: swin_small_patch4_window7_224\n",
      "Temperature: 0.07\n",
      "Data percentages: [5, 10, 20, 30, 50, 100]\n",
      "Classes: ['crazing', 'inclusion', 'patches', 'pitted_surface', 'rolled-in_scale', 'scratches']\n",
      "Found 1800 images\n",
      "Found 1800 annotations\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    data_root = Path(\"NEU-DET\")\n",
    "    \n",
    "    defect_classes = ['crazing', 'inclusion', 'patches', 'pitted_surface', 'rolled-in_scale', 'scratches']\n",
    "    num_classes = 6\n",
    "    class_to_idx = {cls: idx for idx, cls in enumerate(defect_classes)}\n",
    "    \n",
    "    # Focus on meaningful data sizes (skip 1-2% that cause instability)\n",
    "    data_percentages = [5, 10, 20, 30, 50, 100]\n",
    "    samples_per_class = {5: 15, 10: 30, 20: 60, 30: 90, 50: 150, 100: 300}\n",
    "    \n",
    "    # Model settings (proven to work well)\n",
    "    backbone = \"swin_small_patch4_window7_224\"\n",
    "    image_size = 224\n",
    "    projection_dim = 256\n",
    "    hidden_dim = 512\n",
    "    temperature = 0.07  # From successful implementation\n",
    "    \n",
    "    # Training settings (optimized for stability)\n",
    "    batch_size = 8\n",
    "    num_workers = 0  # Avoid multiprocessing issues\n",
    "    pin_memory = False  # Simplify memory management\n",
    "    \n",
    "    contrastive_lr = 1e-4\n",
    "    classification_lr = 5e-5\n",
    "    weight_decay = 0.01\n",
    "    \n",
    "    contrastive_epochs = 10  # Reduced for faster execution\n",
    "    classification_epochs = 20\n",
    "    \n",
    "    # Cross-validation\n",
    "    n_folds = 5\n",
    "    random_state = 42\n",
    "    \n",
    "    # Early stopping\n",
    "    patience = 5\n",
    "    min_delta = 0.001\n",
    "\n",
    "config = Config()\n",
    "\n",
    "print(\"Streamlined Steel Defect Detection\")\n",
    "print(f\"Data root: {config.data_root}\")\n",
    "print(f\"Backbone: {config.backbone}\")\n",
    "print(f\"Temperature: {config.temperature}\")\n",
    "print(f\"Data percentages: {config.data_percentages}\")\n",
    "print(f\"Classes: {config.defect_classes}\")\n",
    "\n",
    "# Verify dataset\n",
    "images_dir = config.data_root / \"images\"\n",
    "annotations_dir = config.data_root / \"annotations\"\n",
    "\n",
    "if images_dir.exists():\n",
    "    image_count = len(list(images_dir.glob(\"*.jpg\")))\n",
    "    print(f\"Found {image_count} images\")\n",
    "else:\n",
    "    print(\"Images directory not found\")\n",
    "\n",
    "if annotations_dir.exists():\n",
    "    annotation_count = len(list(annotations_dir.glob(\"*.xml\")))\n",
    "    print(f\"Found {annotation_count} annotations\")\n",
    "else:\n",
    "    print(\"Annotations directory not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a58251dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Class mapping: {'crazing': 0, 'inclusion': 1, 'patches': 2, 'pitted_surface': 3, 'rolled-in_scale': 4, 'scratches': 5}\n",
      "Found 1800 image files\n",
      "Successfully loaded 1800 samples\n",
      "Class distribution:\n",
      "  crazing: 300 samples\n",
      "  inclusion: 300 samples\n",
      "  patches: 300 samples\n",
      "  pitted_surface: 300 samples\n",
      "  rolled-in_scale: 300 samples\n",
      "  scratches: 300 samples\n",
      "Dataset loaded: 1800 samples\n",
      "Data loading setup complete\n"
     ]
    }
   ],
   "source": [
    "def parse_xml_annotation(xml_path, class_to_idx):\n",
    "    try:\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        objects = root.findall('.//name')\n",
    "        if objects:\n",
    "            defect_name = objects[0].text\n",
    "            if defect_name in class_to_idx:\n",
    "                return class_to_idx[defect_name]\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def load_dataset(data_root):\n",
    "    images_dir = data_root / \"images\"\n",
    "    annotations_dir = data_root / \"annotations\"\n",
    "    \n",
    "    print(f\"Class mapping: {config.class_to_idx}\")\n",
    "    \n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    image_files = list(images_dir.glob(\"*.jpg\"))\n",
    "    print(f\"Found {len(image_files)} image files\")\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        xml_path = annotations_dir / (img_path.stem + '.xml')\n",
    "        \n",
    "        if xml_path.exists():\n",
    "            label = parse_xml_annotation(xml_path, config.class_to_idx)\n",
    "            if label is not None:\n",
    "                image_paths.append(img_path)\n",
    "                labels.append(int(label))\n",
    "    \n",
    "    print(f\"Successfully loaded {len(image_paths)} samples\")\n",
    "    \n",
    "    label_counts = Counter(labels)\n",
    "    print(\"Class distribution:\")\n",
    "    for class_idx, count in sorted(label_counts.items()):\n",
    "        class_name = config.defect_classes[class_idx]\n",
    "        print(f\"  {class_name}: {count} samples\")\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None, mode='classification'):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = str(self.image_paths[idx])\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            if self.mode == 'contrastive':\n",
    "                view1 = self.transform(image=image)['image']\n",
    "                view2 = self.transform(image=image)['image']\n",
    "                return view1, view2, label\n",
    "            else:\n",
    "                transformed = self.transform(image=image)\n",
    "                image = transformed['image']\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def get_transforms(image_size=224, mode='train'):\n",
    "    if mode == 'train':\n",
    "        transform = A.Compose([\n",
    "            A.Resize(height=image_size, width=image_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.3),\n",
    "            A.Rotate(limit=15, p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.6),\n",
    "            A.GaussNoise(var_limit=(10, 50), p=0.2),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    else:\n",
    "        transform = A.Compose([\n",
    "            A.Resize(height=image_size, width=image_size),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    \n",
    "    return transform\n",
    "\n",
    "def create_data_subset(image_paths, labels, percentage, random_state=42):\n",
    "    if percentage >= 100:\n",
    "        return image_paths, labels\n",
    "    \n",
    "    samples_per_class = config.samples_per_class[percentage]\n",
    "    \n",
    "    subset_paths = []\n",
    "    subset_labels = []\n",
    "    \n",
    "    for class_idx in range(config.num_classes):\n",
    "        class_indices = [i for i, label in enumerate(labels) if int(label) == class_idx]\n",
    "        \n",
    "        if len(class_indices) >= samples_per_class:\n",
    "            np.random.seed(random_state + class_idx)\n",
    "            selected_indices = np.random.choice(class_indices, samples_per_class, replace=False)\n",
    "            \n",
    "            for idx in selected_indices:\n",
    "                subset_paths.append(image_paths[idx])\n",
    "                subset_labels.append(int(labels[idx]))\n",
    "    \n",
    "    print(f\"Created {percentage}% subset: {len(subset_paths)} samples ({samples_per_class} per class)\")\n",
    "    return subset_paths, subset_labels\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "image_paths, labels = load_dataset(config.data_root)\n",
    "print(f\"Dataset loaded: {len(image_paths)} samples\")\n",
    "print(\"Data loading setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac7e7f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 05:46:09,611 - INFO - Loading pretrained weights from Hugging Face hub (timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k)\n",
      "2025-07-09 05:46:09,934 - INFO - [timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone feature dimension: 768\n",
      "Model created: 49,957,776 parameters\n",
      "Contrastive output shape: torch.Size([8, 256])\n",
      "Classification output shape: torch.Size([4, 6])\n",
      "Model architecture completed\n"
     ]
    }
   ],
   "source": [
    "class SwinBackbone(nn.Module):\n",
    "    def __init__(self, model_name=\"swin_small_patch4_window7_224\", pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            model_name, \n",
    "            pretrained=pretrained, \n",
    "            num_classes=0,\n",
    "            global_pool='avg'\n",
    "        )\n",
    "        \n",
    "        self.feature_dim = self.backbone.num_features\n",
    "        print(f\"Backbone feature dimension: {self.feature_dim}\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return features\n",
    "\n",
    "class ContrastiveHead(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=512, output_dim=256, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            nn.Linear(hidden_dim // 2, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.head(x), dim=1)\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.head(x)\n",
    "\n",
    "class SupervisedContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07, base_temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.base_temperature = base_temperature\n",
    "    \n",
    "    def forward(self, features, labels):\n",
    "        device = features.device\n",
    "        batch_size = features.shape[0] // 2\n",
    "        \n",
    "        features = features.view(2, batch_size, -1)\n",
    "        \n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        \n",
    "        contrast_features = torch.cat(torch.unbind(features, dim=0), dim=0)\n",
    "        \n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(contrast_features, contrast_features.T),\n",
    "            self.temperature\n",
    "        )\n",
    "        \n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "        \n",
    "        mask = mask.repeat(2, 2)\n",
    "        logits_mask = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size * 2).view(-1, 1).to(device),\n",
    "            0\n",
    "        )\n",
    "        mask = mask * logits_mask\n",
    "        \n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "        \n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n",
    "        loss = -(self.temperature / self.base_temperature) * mean_log_prob_pos\n",
    "        loss = loss.view(2, batch_size).mean()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "class SteelDefectModel(nn.Module):\n",
    "    def __init__(self, num_classes=6, projection_dim=256, model_name=\"swin_small_patch4_window7_224\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = SwinBackbone(model_name)\n",
    "        self.contrastive_head = ContrastiveHead(\n",
    "            self.backbone.feature_dim, \n",
    "            output_dim=projection_dim\n",
    "        )\n",
    "        self.classification_head = ClassificationHead(\n",
    "            self.backbone.feature_dim, \n",
    "            num_classes\n",
    "        )\n",
    "        \n",
    "        self.contrastive_loss = SupervisedContrastiveLoss(temperature=config.temperature)\n",
    "        self.classification_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.mode = 'classification'\n",
    "        \n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        print(f\"Model created: {total_params:,} parameters\")\n",
    "    \n",
    "    def set_mode(self, mode):\n",
    "        self.mode = mode\n",
    "    \n",
    "    def forward(self, x1, x2=None):\n",
    "        if self.mode == 'contrastive':\n",
    "            features1 = self.backbone(x1)\n",
    "            features2 = self.backbone(x2)\n",
    "            proj1 = self.contrastive_head(features1)\n",
    "            proj2 = self.contrastive_head(features2)\n",
    "            return torch.cat([proj1, proj2], dim=0)\n",
    "        else:\n",
    "            features = self.backbone(x1)\n",
    "            return self.classification_head(features)\n",
    "    \n",
    "    def compute_loss(self, outputs, labels):\n",
    "        if self.mode == 'contrastive':\n",
    "            return self.contrastive_loss(outputs, labels)\n",
    "        else:\n",
    "            return self.classification_loss(outputs, labels)\n",
    "\n",
    "print(\"Creating model...\")\n",
    "model = SteelDefectModel(num_classes=config.num_classes, projection_dim=config.projection_dim)\n",
    "model = model.to(device)\n",
    "\n",
    "# Test model\n",
    "test_batch = torch.randn(4, 3, 224, 224).to(device)\n",
    "test_labels = torch.tensor([0, 1, 2, 3]).to(device)\n",
    "\n",
    "model.set_mode('contrastive')\n",
    "with torch.no_grad():\n",
    "    contrastive_out = model(test_batch, test_batch)\n",
    "    print(f\"Contrastive output shape: {contrastive_out.shape}\")\n",
    "\n",
    "model.set_mode('classification')\n",
    "with torch.no_grad():\n",
    "    classification_out = model(test_batch)\n",
    "    print(f\"Classification output shape: {classification_out.shape}\")\n",
    "\n",
    "print(\"Model architecture completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e33cb5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions loaded\n",
      "Ready for experiments\n"
     ]
    }
   ],
   "source": [
    "def train_contrastive_phase(model, loader, epochs=10):\n",
    "    model.set_mode('contrastive')\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.contrastive_lr, weight_decay=config.weight_decay)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for view1, view2, labels in loader:\n",
    "            view1, view2, labels = view1.to(device), view2.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(view1, view2)\n",
    "            loss = model.compute_loss(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        scheduler.step()\n",
    "        avg_loss = total_loss / max(num_batches, 1)\n",
    "        \n",
    "        if (epoch + 1) % 3 == 0:\n",
    "            print(f\"    Contrastive Epoch {epoch+1}/{epochs}: Loss = {avg_loss:.4f}\")\n",
    "\n",
    "def train_classification_phase(model, train_loader, val_loader, epochs=20):\n",
    "    model.set_mode('classification')\n",
    "    \n",
    "    # Progressive unfreezing strategy\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.classification_head.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.classification_lr, weight_decay=config.weight_decay)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=epochs//3, gamma=0.5)\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = model.compute_loss(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_acc = 100 * correct / total\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Unfreeze backbone halfway through\n",
    "        if epoch == epochs // 2:\n",
    "            print(f\"    Unfreezing backbone at epoch {epoch+1}\")\n",
    "            for param in model.backbone.parameters():\n",
    "                param.requires_grad = True\n",
    "            \n",
    "            # Update optimizer with new parameters\n",
    "            optimizer = optim.AdamW([\n",
    "                {'params': model.classification_head.parameters(), 'lr': config.classification_lr},\n",
    "                {'params': model.backbone.parameters(), 'lr': config.classification_lr * 0.1}\n",
    "            ], weight_decay=config.weight_decay)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"    Classification Epoch {epoch+1}/{epochs}: Val Acc = {val_acc:.2f}%\")\n",
    "        \n",
    "        if patience_counter >= config.patience:\n",
    "            print(f\"    Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    return best_val_acc\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'f1_macro': f1_macro\n",
    "    }\n",
    "\n",
    "def run_single_fold(train_paths, train_labels, val_paths, val_labels):\n",
    "    # Create model\n",
    "    model = SteelDefectModel(num_classes=config.num_classes, projection_dim=config.projection_dim)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Create datasets\n",
    "    contrastive_dataset = SimpleDataset(train_paths, train_labels, \n",
    "                                      get_transforms(config.image_size, 'train'), 'contrastive')\n",
    "    train_dataset = SimpleDataset(train_paths, train_labels, \n",
    "                                get_transforms(config.image_size, 'train'))\n",
    "    val_dataset = SimpleDataset(val_paths, val_labels, \n",
    "                              get_transforms(config.image_size, 'val'))\n",
    "    \n",
    "    # Create dataloaders\n",
    "    batch_size = min(config.batch_size, len(train_paths))\n",
    "    \n",
    "    contrastive_loader = DataLoader(contrastive_dataset, batch_size=batch_size, \n",
    "                                  shuffle=True, num_workers=config.num_workers, drop_last=False)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                            shuffle=True, num_workers=config.num_workers, drop_last=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, \n",
    "                          shuffle=False, num_workers=config.num_workers, drop_last=False)\n",
    "    \n",
    "    print(\"    Phase 1: Contrastive Learning\")\n",
    "    train_contrastive_phase(model, contrastive_loader, config.contrastive_epochs)\n",
    "    \n",
    "    print(\"    Phase 2: Classification\")\n",
    "    best_val_acc = train_classification_phase(model, train_loader, val_loader, config.classification_epochs)\n",
    "    \n",
    "    results = evaluate_model(model, val_loader)\n",
    "    results['best_val_acc'] = best_val_acc\n",
    "    \n",
    "    del model\n",
    "    clear_memory()\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Training functions loaded\")\n",
    "print(\"Ready for experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaa1625e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "Using data percentages that avoid instability\n",
      "================================================================================\n",
      "STEEL DEFECT DETECTION EXPERIMENT\n",
      "================================================================================\n",
      "Total samples: 1800\n",
      "Data percentages: [5, 10, 20]\n",
      "Method: Swin Transformer + Contrastive Learning\n",
      "Temperature: 0.07\n",
      "================================================================================\n",
      "\n",
      "Running experiment for 5% data\n",
      "--------------------------------------------------\n",
      "Created 5% subset: 90 samples (15 per class)\n",
      "Using 3-fold cross-validation\n",
      "  Fold 1/3\n",
      "    Train: 60, Val: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 05:53:38,185 - INFO - Loading pretrained weights from Hugging Face hub (timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k)\n",
      "2025-07-09 05:53:38,506 - INFO - [timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone feature dimension: 768\n",
      "Model created: 49,957,776 parameters\n",
      "    Phase 1: Contrastive Learning\n",
      "    Contrastive Epoch 3/10: Loss = 2.5461\n",
      "    Contrastive Epoch 6/10: Loss = 2.0872\n",
      "    Contrastive Epoch 9/10: Loss = 2.0344\n",
      "    Phase 2: Classification\n",
      "    Classification Epoch 5/20: Val Acc = 73.33%\n",
      "    Classification Epoch 10/20: Val Acc = 76.67%\n",
      "    Unfreezing backbone at epoch 11\n",
      "    Classification Epoch 15/20: Val Acc = 83.33%\n",
      "    Classification Epoch 20/20: Val Acc = 90.00%\n",
      "    Results: Acc=0.900, F1=0.898\n",
      "  Fold 2/3\n",
      "    Train: 60, Val: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 05:54:27,141 - INFO - Loading pretrained weights from Hugging Face hub (timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k)\n",
      "2025-07-09 05:54:27,972 - INFO - [timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone feature dimension: 768\n",
      "Model created: 49,957,776 parameters\n",
      "    Phase 1: Contrastive Learning\n",
      "    Contrastive Epoch 3/10: Loss = 2.4705\n",
      "    Contrastive Epoch 6/10: Loss = 1.9305\n",
      "    Contrastive Epoch 9/10: Loss = 1.9239\n",
      "    Phase 2: Classification\n",
      "    Classification Epoch 5/20: Val Acc = 86.67%\n",
      "    Classification Epoch 10/20: Val Acc = 90.00%\n",
      "    Unfreezing backbone at epoch 11\n",
      "    Classification Epoch 15/20: Val Acc = 93.33%\n",
      "    Early stopping at epoch 17\n",
      "    Results: Acc=0.933, F1=0.933\n",
      "  Fold 3/3\n",
      "    Train: 60, Val: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 05:55:11,711 - INFO - Loading pretrained weights from Hugging Face hub (timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k)\n",
      "2025-07-09 05:55:12,034 - INFO - [timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone feature dimension: 768\n",
      "Model created: 49,957,776 parameters\n",
      "    Phase 1: Contrastive Learning\n",
      "    Contrastive Epoch 3/10: Loss = 2.0683\n",
      "    Contrastive Epoch 6/10: Loss = 2.0741\n",
      "    Contrastive Epoch 9/10: Loss = 1.4457\n",
      "    Phase 2: Classification\n",
      "    Classification Epoch 5/20: Val Acc = 96.67%\n",
      "    Classification Epoch 10/20: Val Acc = 96.67%\n",
      "    Early stopping at epoch 10\n",
      "    Results: Acc=0.967, F1=0.966\n",
      "Summary for 5%:\n",
      "  Mean Accuracy: 0.933 ± 0.027\n",
      "  Mean F1: 0.932 ± 0.028\n",
      "  Completed folds: 3/3\n",
      "\n",
      "Running experiment for 10% data\n",
      "--------------------------------------------------\n",
      "Created 10% subset: 180 samples (30 per class)\n",
      "Using 3-fold cross-validation\n",
      "  Fold 1/3\n",
      "    Train: 120, Val: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 05:55:45,502 - INFO - Loading pretrained weights from Hugging Face hub (timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k)\n",
      "2025-07-09 05:55:45,825 - INFO - [timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone feature dimension: 768\n",
      "Model created: 49,957,776 parameters\n",
      "    Phase 1: Contrastive Learning\n",
      "    Contrastive Epoch 3/10: Loss = 1.9696\n",
      "    Contrastive Epoch 6/10: Loss = 1.6330\n",
      "    Contrastive Epoch 9/10: Loss = 1.4335\n",
      "    Phase 2: Classification\n",
      "    Classification Epoch 5/20: Val Acc = 98.33%\n",
      "    Classification Epoch 10/20: Val Acc = 100.00%\n",
      "    Unfreezing backbone at epoch 11\n",
      "    Early stopping at epoch 13\n",
      "    Results: Acc=1.000, F1=1.000\n",
      "  Fold 2/3\n",
      "    Train: 120, Val: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 05:56:57,425 - INFO - Loading pretrained weights from Hugging Face hub (timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k)\n",
      "2025-07-09 05:56:57,757 - INFO - [timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone feature dimension: 768\n",
      "Model created: 49,957,776 parameters\n",
      "    Phase 1: Contrastive Learning\n",
      "    Contrastive Epoch 3/10: Loss = 2.1862\n",
      "    Contrastive Epoch 6/10: Loss = 1.8529\n",
      "    Contrastive Epoch 9/10: Loss = 1.6807\n",
      "    Phase 2: Classification\n",
      "    Classification Epoch 5/20: Val Acc = 98.33%\n",
      "    Early stopping at epoch 9\n",
      "    Results: Acc=0.983, F1=0.983\n",
      "  Fold 3/3\n",
      "    Train: 120, Val: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 05:58:00,779 - INFO - Loading pretrained weights from Hugging Face hub (timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k)\n",
      "2025-07-09 05:58:01,097 - INFO - [timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone feature dimension: 768\n",
      "Model created: 49,957,776 parameters\n",
      "    Phase 1: Contrastive Learning\n",
      "    Contrastive Epoch 3/10: Loss = 2.3194\n",
      "    Contrastive Epoch 6/10: Loss = 1.6952\n",
      "    Contrastive Epoch 9/10: Loss = 1.3229\n",
      "    Phase 2: Classification\n",
      "    Classification Epoch 5/20: Val Acc = 98.33%\n",
      "    Early stopping at epoch 8\n",
      "    Results: Acc=0.983, F1=0.983\n",
      "Summary for 10%:\n",
      "  Mean Accuracy: 0.989 ± 0.008\n",
      "  Mean F1: 0.989 ± 0.008\n",
      "  Completed folds: 3/3\n",
      "\n",
      "Running experiment for 20% data\n",
      "--------------------------------------------------\n",
      "Created 20% subset: 360 samples (60 per class)\n",
      "Using 5-fold cross-validation\n",
      "  Fold 1/5\n",
      "    Train: 288, Val: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 05:59:02,439 - INFO - Loading pretrained weights from Hugging Face hub (timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k)\n",
      "2025-07-09 05:59:02,759 - INFO - [timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone feature dimension: 768\n",
      "Model created: 49,957,776 parameters\n",
      "    Phase 1: Contrastive Learning\n",
      "    Contrastive Epoch 3/10: Loss = 1.6305\n",
      "    Contrastive Epoch 6/10: Loss = 1.2318\n",
      "    Contrastive Epoch 9/10: Loss = 1.0399\n",
      "    Phase 2: Classification\n",
      "    Classification Epoch 5/20: Val Acc = 100.00%\n",
      "    Early stopping at epoch 6\n",
      "    Results: Acc=1.000, F1=1.000\n",
      "  Fold 2/5\n",
      "    Train: 288, Val: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 06:01:19,405 - INFO - Loading pretrained weights from Hugging Face hub (timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k)\n",
      "2025-07-09 06:01:19,725 - INFO - [timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone feature dimension: 768\n",
      "Model created: 49,957,776 parameters\n",
      "    Phase 1: Contrastive Learning\n",
      "    Contrastive Epoch 3/10: Loss = 1.7117\n",
      "    Contrastive Epoch 6/10: Loss = 1.2095\n",
      "    Contrastive Epoch 9/10: Loss = 1.0592\n",
      "    Phase 2: Classification\n",
      "    Classification Epoch 5/20: Val Acc = 100.00%\n",
      "    Early stopping at epoch 6\n",
      "    Results: Acc=1.000, F1=1.000\n",
      "  Fold 3/5\n",
      "    Train: 288, Val: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 06:03:35,304 - INFO - Loading pretrained weights from Hugging Face hub (timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k)\n",
      "2025-07-09 06:03:35,623 - INFO - [timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone feature dimension: 768\n",
      "Model created: 49,957,776 parameters\n",
      "    Phase 1: Contrastive Learning\n",
      "    Contrastive Epoch 3/10: Loss = 1.6412\n",
      "    Contrastive Epoch 6/10: Loss = 1.2111\n",
      "    Contrastive Epoch 9/10: Loss = 1.1921\n",
      "    Phase 2: Classification\n",
      "    Classification Epoch 5/20: Val Acc = 98.61%\n",
      "    Early stopping at epoch 6\n",
      "    Results: Acc=0.986, F1=0.986\n",
      "  Fold 4/5\n",
      "    Train: 288, Val: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 06:05:54,490 - INFO - Loading pretrained weights from Hugging Face hub (timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k)\n",
      "2025-07-09 06:05:55,268 - INFO - [timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone feature dimension: 768\n",
      "Model created: 49,957,776 parameters\n",
      "    Phase 1: Contrastive Learning\n",
      "    Contrastive Epoch 3/10: Loss = 1.7086\n",
      "    Contrastive Epoch 6/10: Loss = 1.3376\n",
      "    Contrastive Epoch 9/10: Loss = 1.1496\n",
      "    Phase 2: Classification\n",
      "    Classification Epoch 5/20: Val Acc = 100.00%\n",
      "    Early stopping at epoch 6\n",
      "    Results: Acc=1.000, F1=1.000\n",
      "  Fold 5/5\n",
      "    Train: 288, Val: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 06:08:14,184 - INFO - Loading pretrained weights from Hugging Face hub (timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k)\n",
      "2025-07-09 06:08:14,511 - INFO - [timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone feature dimension: 768\n",
      "Model created: 49,957,776 parameters\n",
      "    Phase 1: Contrastive Learning\n",
      "    Contrastive Epoch 3/10: Loss = 1.6779\n",
      "    Contrastive Epoch 6/10: Loss = 1.3648\n",
      "    Contrastive Epoch 9/10: Loss = 1.1553\n",
      "    Phase 2: Classification\n",
      "    Classification Epoch 5/20: Val Acc = 98.61%\n",
      "    Early stopping at epoch 6\n",
      "    Results: Acc=0.986, F1=0.986\n",
      "Summary for 20%:\n",
      "  Mean Accuracy: 0.994 ± 0.007\n",
      "  Mean F1: 0.994 ± 0.007\n",
      "  Completed folds: 5/5\n",
      "\n",
      "================================================================================\n",
      "FINAL RESULTS\n",
      "================================================================================\n",
      "%Data    Mean Acc     Std Acc      Mean F1      Std F1       Folds   \n",
      "----------------------------------------------------------------------\n",
      "5        0.933        0.027        0.932        0.028        3       \n",
      "10       0.989        0.008        0.989        0.008        3       \n",
      "20       0.994        0.007        0.994        0.007        5       \n",
      "\n",
      "Total experiment time: 16.9 minutes\n",
      "\n",
      "Best result: 20% data\n",
      "  Accuracy: 0.994 ± 0.007\n",
      "  F1-Score: 0.994 ± 0.007\n"
     ]
    }
   ],
   "source": [
    "def run_experiment_for_percentage(image_paths, labels, percentage):\n",
    "    print(f\"\\nRunning experiment for {percentage}% data\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    subset_paths, subset_labels = create_data_subset(image_paths, labels, percentage)\n",
    "    \n",
    "    n_splits = 3 if percentage <= 10 else 5\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=config.random_state)\n",
    "    print(f\"Using {n_splits}-fold cross-validation\")\n",
    "    \n",
    "    fold_results = []\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(subset_paths, subset_labels)):\n",
    "        print(f\"  Fold {fold_idx + 1}/{n_splits}\")\n",
    "        \n",
    "        train_paths = [subset_paths[i] for i in train_idx]\n",
    "        train_labels = [subset_labels[i] for i in train_idx]\n",
    "        val_paths = [subset_paths[i] for i in val_idx]\n",
    "        val_labels = [subset_labels[i] for i in val_idx]\n",
    "        \n",
    "        print(f\"    Train: {len(train_paths)}, Val: {len(val_paths)}\")\n",
    "        \n",
    "        try:\n",
    "            results = run_single_fold(train_paths, train_labels, val_paths, val_labels)\n",
    "            fold_results.append(results)\n",
    "            \n",
    "            print(f\"    Results: Acc={results['accuracy']:.3f}, F1={results['f1_weighted']:.3f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Fold {fold_idx + 1} failed: {e}\")\n",
    "            clear_memory()\n",
    "            continue\n",
    "    \n",
    "    if fold_results:\n",
    "        accuracies = [r['accuracy'] for r in fold_results]\n",
    "        f1_scores = [r['f1_weighted'] for r in fold_results]\n",
    "        \n",
    "        summary = {\n",
    "            'percentage': percentage,\n",
    "            'n_folds': len(fold_results),\n",
    "            'cv_splits': n_splits,\n",
    "            'mean_accuracy': np.mean(accuracies),\n",
    "            'std_accuracy': np.std(accuracies),\n",
    "            'mean_f1': np.mean(f1_scores),\n",
    "            'std_f1': np.std(f1_scores),\n",
    "            'fold_results': fold_results\n",
    "        }\n",
    "        \n",
    "        print(f\"Summary for {percentage}%:\")\n",
    "        print(f\"  Mean Accuracy: {summary['mean_accuracy']:.3f} ± {summary['std_accuracy']:.3f}\")\n",
    "        print(f\"  Mean F1: {summary['mean_f1']:.3f} ± {summary['std_f1']:.3f}\")\n",
    "        print(f\"  Completed folds: {summary['n_folds']}/{n_splits}\")\n",
    "        \n",
    "        return summary\n",
    "    else:\n",
    "        print(f\"No successful folds for {percentage}%\")\n",
    "        return None\n",
    "\n",
    "def run_experiment(image_paths, labels, data_percentages):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"STEEL DEFECT DETECTION EXPERIMENT\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total samples: {len(image_paths)}\")\n",
    "    print(f\"Data percentages: {data_percentages}\")\n",
    "    print(f\"Method: Swin Transformer + Contrastive Learning\")\n",
    "    print(f\"Temperature: {config.temperature}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    all_results = {}\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for percentage in data_percentages:\n",
    "        try:\n",
    "            results = run_experiment_for_percentage(image_paths, labels, percentage)\n",
    "            if results:\n",
    "                all_results[percentage] = results\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Experiment failed for {percentage}%: {e}\")\n",
    "            clear_memory()\n",
    "            continue\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'%Data':<8} {'Mean Acc':<12} {'Std Acc':<12} {'Mean F1':<12} {'Std F1':<12} {'Folds':<8}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for percentage in sorted(all_results.keys()):\n",
    "        r = all_results[percentage]\n",
    "        print(f\"{percentage:<8} {r['mean_accuracy']:<12.3f} {r['std_accuracy']:<12.3f} \"\n",
    "              f\"{r['mean_f1']:<12.3f} {r['std_f1']:<12.3f} {r['n_folds']:<8}\")\n",
    "    \n",
    "    print(f\"\\nTotal experiment time: {total_time/60:.1f} minutes\")\n",
    "    \n",
    "    if all_results:\n",
    "        best_pct = max(all_results.keys(), key=lambda x: all_results[x]['mean_f1'])\n",
    "        best_result = all_results[best_pct]\n",
    "        print(f\"\\nBest result: {best_pct}% data\")\n",
    "        print(f\"  Accuracy: {best_result['mean_accuracy']:.3f} ± {best_result['std_accuracy']:.3f}\")\n",
    "        print(f\"  F1-Score: {best_result['mean_f1']:.3f} ± {best_result['std_f1']:.3f}\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Run experiment with meaningful data sizes\n",
    "print(\"Starting experiment...\")\n",
    "print(\"Using data percentages that avoid instability\")\n",
    "\n",
    "# Test with a few percentages first\n",
    "test_percentages = [5, 10, 20]\n",
    "results = run_experiment(image_paths, labels, test_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe534e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
